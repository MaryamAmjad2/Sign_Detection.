# Sign Detection Project - ASL Gestures  

This project detects three American Sign Language (ASL) gestures: **"Hello," "Thank You,"** and **"I Love You."** It utilizes **MediaPipe Holistic** to capture hand, face, and pose landmarks, while **TensorFlow** is used for deep learning-based gesture classification. **OpenCV** handles real-time video processing, and **NumPy & Pandas** assist with data preprocessing and storage.

## Features  
- **Real-time ASL sign detection** using MediaPipe Holistic.  
- **Deep learning-based classification** with TensorFlow.  
- **OpenCV integration** for processing live video streams.  
- **NumPy & Pandas** for efficient data handling and preprocessing.  

## Tech Stack  
- **MediaPipe Holistic** â€“ Extracts hand, face, and pose keypoints.  
- **TensorFlow** â€“ Trains and classifies ASL gestures.  
- **OpenCV** â€“ Handles video input for real-time detection.  
- **NumPy & Pandas** â€“ Assist in data preprocessing and storage.  

## Usage  
1. Capture ASL gestures using a webcam.  
2. Extract keypoints using MediaPipe Holistic.  
3. Train a deep learning model with TensorFlow.  
4. Detect and classify signs in real-time.  

## Applications  
- Assistive technology for speech-impaired individuals.  
- ASL learning and educational tools.  
- Gesture-based human-computer interaction.  

Contributions are welcome! ðŸš€  
